{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device_str = 'cuda'\n",
    "generator = torch.Generator(device=device_str)"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-06-21T11:56:51.804753Z",
     "iopub.execute_input": "2023-06-21T11:56:51.805117Z",
     "iopub.status.idle": "2023-06-21T11:56:51.809982Z",
     "shell.execute_reply.started": "2023-06-21T11:56:51.805078Z",
     "shell.execute_reply": "2023-06-21T11:56:51.808939Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def read_data():\n",
    "    with open('/kaggle/input/qa-persian/data.jsonl', 'r') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:56:51.854035Z",
     "iopub.execute_input": "2023-06-21T11:56:51.854742Z",
     "iopub.status.idle": "2023-06-21T11:56:51.859708Z",
     "shell.execute_reply.started": "2023-06-21T11:56:51.854706Z",
     "shell.execute_reply": "2023-06-21T11:56:51.858521Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "texts = ''.join([(d['text'] or '') + (d['answer'] or '') for d in read_data()])\n",
    "chars = Counter(texts)\n",
    "chars = ['<s>'] + [c for c, cnt in chars.most_common() if cnt >= 1000]\n",
    "ctoi = {c: i for i, c in enumerate(chars)}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:56:51.896739Z",
     "iopub.execute_input": "2023-06-21T11:56:51.897391Z",
     "iopub.status.idle": "2023-06-21T11:57:10.120917Z",
     "shell.execute_reply.started": "2023-06-21T11:56:51.897354Z",
     "shell.execute_reply": "2023-06-21T11:57:10.119906Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "conc = []\n",
    "for i, d in enumerate(read_data()):\n",
    "    conc += ['<s>']\n",
    "    conc += list(d['text'] or '')\n",
    "    conc += ['<s>']\n",
    "    conc += list(d['answer'] or '')\n",
    "    if i == 10000:\n",
    "        break\n",
    "X = []\n",
    "for x in conc:\n",
    "    if x in chars:\n",
    "        X.append(ctoi[x])\n",
    "X = torch.tensor(X, device=device_str)\n",
    "X.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:57:10.122730Z",
     "iopub.execute_input": "2023-06-21T11:57:10.123066Z",
     "iopub.status.idle": "2023-06-21T11:57:15.410882Z",
     "shell.execute_reply.started": "2023-06-21T11:57:10.123033Z",
     "shell.execute_reply": "2023-06-21T11:57:15.409797Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([5156519])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "window_len = 10\n",
    "X_train = torch.concat([X[i:len(X) - window_len + i].view(-1, 1) for i in range(window_len)], dim=1)\n",
    "y_train = X[window_len:]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:57:15.412247Z",
     "iopub.execute_input": "2023-06-21T11:57:15.412707Z",
     "iopub.status.idle": "2023-06-21T11:57:15.421782Z",
     "shell.execute_reply.started": "2023-06-21T11:57:15.412675Z",
     "shell.execute_reply": "2023-06-21T11:57:15.420678Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Correct initialization does not matter much in small models\n",
    "Wemb = torch.randn((len(chars), 10), generator=generator, device=device_str)\n",
    "W1 = torch.randn((10 * window_len, 100), generator=generator, device=device_str) * 0.01\n",
    "b1 = torch.randn((100,), generator=generator, device=device_str) * 0.01\n",
    "W2 = torch.randn((100, 100), generator=generator, device=device_str) * 0.01\n",
    "b2 = torch.randn((100,), generator=generator, device=device_str) * 0.01\n",
    "W3 = torch.randn((100, len(chars)), generator=generator, device=device_str) * 0.01\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, Wemb]\n",
    "for p in params:\n",
    "    p.requires_grad = True\n",
    "sum(p.nelement() for p in params)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:59:13.651187Z",
     "iopub.execute_input": "2023-06-21T11:59:13.651875Z",
     "iopub.status.idle": "2023-06-21T11:59:13.666416Z",
     "shell.execute_reply.started": "2023-06-21T11:59:13.651837Z",
     "shell.execute_reply": "2023-06-21T11:59:13.665190Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "execution_count": 21,
     "output_type": "execute_result",
     "data": {
      "text/plain": "41980"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 256\n",
    "for i in tqdm(range(1000000)):\n",
    "    inds = torch.randint(0, X_train.shape[0], (batch_size,), generator=generator, device=device_str)\n",
    "    emb = Wemb[X_train[inds]]\n",
    "    a = torch.tanh(torch.tanh(emb.view(batch_size, -1) @ W1 + b1) @ W2 + b2) @ W3\n",
    "    loss = F.cross_entropy(a, y_train[inds])\n",
    "    #ae = torch.exp(a)\n",
    "    #se = torch.sum(ae, dim=1, keepdim=True)\n",
    "    #res = ae / se\n",
    "    #loss = -torch.sum(torch.log(res[np.linspace(0, batch_size - 1, num=batch_size, dtype=np.int32), y_train[inds]])) / batch_size\n",
    "   \n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    lr = 0.01 if i < 30000 else 0.001\n",
    "    for p in params:\n",
    "        p.data -= p.grad * lr\n",
    "    if i % 100000 == 0:\n",
    "        print(loss.item())\n",
    "    #print(res[])\n",
    "#Wemb[X_train[0]]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T11:59:14.704779Z",
     "iopub.execute_input": "2023-06-21T11:59:14.705161Z",
     "iopub.status.idle": "2023-06-21T12:15:25.220877Z",
     "shell.execute_reply.started": "2023-06-21T11:59:14.705129Z",
     "shell.execute_reply": "2023-06-21T12:15:25.219842Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "text": "  0%|          | 211/1000000 [00:00<15:51, 1050.82it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "5.288217067718506\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 10%|█         | 100143/1000000 [01:37<14:19, 1047.49it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.9073073863983154\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 20%|██        | 200167/1000000 [03:14<12:32, 1063.27it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.718590497970581\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 30%|███       | 300158/1000000 [04:51<11:03, 1054.64it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.9321165084838867\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 40%|████      | 400159/1000000 [06:28<10:10, 981.97it/s] ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.7805838584899902\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 50%|█████     | 500135/1000000 [08:05<08:00, 1039.76it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.392104387283325\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 60%|██████    | 600159/1000000 [09:42<06:21, 1046.84it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.5016770362854004\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 70%|███████   | 700194/1000000 [11:19<04:45, 1050.17it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.33609938621521\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 80%|████████  | 800182/1000000 [12:56<03:10, 1048.43it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.256413459777832\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 90%|█████████ | 900201/1000000 [14:33<01:35, 1040.55it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.5296003818511963\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 1000000/1000000 [16:10<00:00, 1030.39it/s]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text = ['<s>'] + list('ماست لبنیات است')\n",
    "X_test = []\n",
    "print(''.join(text[:10]))\n",
    "for c in text[:10]:\n",
    "    X_test.append(ctoi[c])\n",
    "X_test = torch.tensor(X_test)\n",
    "with torch.no_grad():\n",
    "    r = torch.tanh(Wemb[X_test].view(1, -1) @ W1 + b1) @ W2\n",
    "    print(chars[torch.argmax(r)])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T12:25:23.427045Z",
     "iopub.execute_input": "2023-06-21T12:25:23.427442Z",
     "iopub.status.idle": "2023-06-21T12:25:23.436089Z",
     "shell.execute_reply.started": "2023-06-21T12:25:23.427411Z",
     "shell.execute_reply": "2023-06-21T12:25:23.435023Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": "<s>ماست لبنی\nف\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}